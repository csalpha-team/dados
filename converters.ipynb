{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e5e79fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dados.raw.utils.postgres_interactions import PostgresETL\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "import basedosdados as bd\n",
    "from typing import Dict, Any"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac27c77",
   "metadata": {},
   "source": [
    "### Geração dos dados de produção rural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74372196",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from typing import Dict, Any\n",
    "import pandas as pd\n",
    "from decimal import Decimal\n",
    "\n",
    "# Função para salvar JSON em arquivo\n",
    "def decimal_default(obj):\n",
    "    \"\"\"\n",
    "    Função auxiliar para converter objetos Decimal para float\n",
    "    durante a serialização JSON.\n",
    "    \"\"\"\n",
    "    if isinstance(obj, Decimal):\n",
    "        return float(obj)\n",
    "    raise TypeError(f\"Object of type {type(obj)} is not JSON serializable\")\n",
    "\n",
    "def save_json(data: Dict[str, Any], filename: str) -> None:\n",
    "    \"\"\"\n",
    "    Salva um dicionário como arquivo JSON.\n",
    "    \n",
    "    Args:\n",
    "        data (Dict[str, Any]): Dicionário a ser salvo\n",
    "        filename (str): Nome do arquivo\n",
    "    \"\"\"\n",
    "    with open(filename, 'w', encoding='utf-8') as f:\n",
    "        json.dump(data, f, ensure_ascii=False, indent=4, default=decimal_default)\n",
    "    print(f\"Arquivo {filename} salvo com sucesso!\")\n",
    "\n",
    "# Já temos os vetores para PEVS e censo combinado conforme código fornecido\n",
    "vetor_valor_pevs = df_to_json(extracao_vegetal_pevs_query, 'valor_producao')\n",
    "vetor_quantidade_pevs = df_to_json(extracao_vegetal_pevs_query, 'quantidade_produzida')\n",
    "censo_combinado = pd.concat([extracao_vegetal_censo_2006_query, extracao_vegetal_censo_2017_query], ignore_index=True)\n",
    "vetor_valor_censo = df_to_json(censo_combinado, 'valor_producao')\n",
    "vetor_quantidade_censo = df_to_json(censo_combinado, 'quantidade_produzida')\n",
    "\n",
    "# Criar vetores para lavoura permanente (PAM)\n",
    "lavoura_permanente_pam_vetores = {\n",
    "    'valor': df_to_json(lavoura_permanente_pam_query, 'valor_producao'),\n",
    "    'quantidade': df_to_json(lavoura_permanente_pam_query, 'quantidade_produzida')\n",
    "}\n",
    "\n",
    "# Criar vetores para lavoura temporária (PAM)\n",
    "lavoura_temporaria_pam_vetores = {\n",
    "    'valor': df_to_json(lavoura_temporaria_pam_query, 'valor_producao'),\n",
    "    'quantidade': df_to_json(lavoura_temporaria_pam_query, 'quantidade_produzida')\n",
    "}\n",
    "\n",
    "# Criar vetores para lavoura permanente (censo combinado)\n",
    "lavoura_permanente_censo_combinado = pd.concat([\n",
    "    lavoura_permanente_censo_2006_query, \n",
    "    lavoura_permanente_censo_2017_query\n",
    "], ignore_index=True)\n",
    "\n",
    "lavoura_permanente_censo_vetores = {\n",
    "    'valor': df_to_json(lavoura_permanente_censo_combinado, 'valor_producao'),\n",
    "    'quantidade': df_to_json(lavoura_permanente_censo_combinado, 'quantidade_produzida')\n",
    "}\n",
    "\n",
    "# Criar vetores para lavoura temporária (censo combinado)\n",
    "lavoura_temporaria_censo_combinado = pd.concat([\n",
    "    lavoura_temporaria_censo_2006_query, \n",
    "    lavoura_temporaria_censo_2017_query\n",
    "], ignore_index=True)\n",
    "\n",
    "lavoura_temporaria_censo_vetores = {\n",
    "    'valor': df_to_json(lavoura_temporaria_censo_combinado, 'valor_producao'),\n",
    "    'quantidade': df_to_json(lavoura_temporaria_censo_combinado, 'quantidade_produzida')\n",
    "}\n",
    "\n",
    "# Criar diretório para os arquivos JSON se não existir\n",
    "output_dir = 'json_output'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Salvar todos os JSONs\n",
    "# PEVS\n",
    "save_json(vetor_valor_pevs, f'{output_dir}/extracao_vegetal_pevs_valor.json')\n",
    "save_json(vetor_quantidade_pevs, f'{output_dir}/extracao_vegetal_pevs_quantidade.json')\n",
    "\n",
    "# Censo Extração Vegetal\n",
    "save_json(vetor_valor_censo, f'{output_dir}/extracao_vegetal_censo_valor.json')\n",
    "save_json(vetor_quantidade_censo, f'{output_dir}/extracao_vegetal_censo_quantidade.json')\n",
    "\n",
    "# Lavoura Permanente PAM\n",
    "save_json(lavoura_permanente_pam_vetores['valor'], f'{output_dir}/lavoura_permanente_pam_valor.json')\n",
    "save_json(lavoura_permanente_pam_vetores['quantidade'], f'{output_dir}/lavoura_permanente_pam_quantidade.json')\n",
    "\n",
    "# Lavoura Temporária PAM\n",
    "save_json(lavoura_temporaria_pam_vetores['valor'], f'{output_dir}/lavoura_temporaria_pam_valor.json')\n",
    "save_json(lavoura_temporaria_pam_vetores['quantidade'], f'{output_dir}/lavoura_temporaria_pam_quantidade.json')\n",
    "\n",
    "# Lavoura Permanente Censo\n",
    "save_json(lavoura_permanente_censo_vetores['valor'], f'{output_dir}/lavoura_permanente_censo_valor.json')\n",
    "save_json(lavoura_permanente_censo_vetores['quantidade'], f'{output_dir}/lavoura_permanente_censo_quantidade.json')\n",
    "\n",
    "# Lavoura Temporária Censo\n",
    "save_json(lavoura_temporaria_censo_vetores['valor'], f'{output_dir}/lavoura_temporaria_censo_valor.json')\n",
    "save_json(lavoura_temporaria_censo_vetores['quantidade'], f'{output_dir}/lavoura_temporaria_censo_quantidade.json')\n",
    "\n",
    "print(\"Todos os arquivos JSON foram gerados com sucesso!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### autoconsumo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-23 22:38:09,413 - PostgresETL - INFO - Connected to database gold_zone at localhost\n",
      "2026-01-23 22:38:09,563 - PostgresETL - INFO - Downloaded 492 rows from database\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processando tabela: extracao_vegetal_censo_2006...\n",
      " -> 492 registros processados.\n",
      "Processando tabela: lavoura_permanente_censo_2006...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-23 22:38:09,672 - PostgresETL - INFO - Downloaded 792 rows from database\n",
      "2026-01-23 22:38:09,767 - PostgresETL - INFO - Downloaded 636 rows from database\n",
      "2026-01-23 22:38:09,885 - PostgresETL - INFO - Downloaded 852 rows from database\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -> 792 registros processados.\n",
      "Processando tabela: lavoura_temporaria_censo_2006_2284...\n",
      " -> 636 registros processados.\n",
      "Processando tabela: lavoura_permanente_censo_2017...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-23 22:38:09,986 - PostgresETL - INFO - Downloaded 636 rows from database\n",
      "2026-01-23 22:38:10,064 - PostgresETL - INFO - Downloaded 660 rows from database\n",
      "2026-01-23 22:38:10,075 - PostgresETL - INFO - Disconnected from database\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -> 852 registros processados.\n",
      "Processando tabela: extracao_vegetal_censo_2017...\n",
      " -> 636 registros processados.\n",
      "Processando tabela: lavoura_temporaria_censo_2017...\n",
      " -> 660 registros processados.\n",
      "\n",
      "Iniciando validação final Pydantic...\n",
      "Arquivo json_output/censos_consolidado_full.json salvo com sucesso!\n"
     ]
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "from typing import Dict, Any\n",
    "from pydantic import BaseModel, Field\n",
    "import os\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from dados.raw.utils.postgres_interactions import PostgresETL\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "CENSUS_TABLE_NAMES = [\n",
    "    \"extracao_vegetal_censo_2006\",\n",
    "    \"lavoura_permanente_censo_2006\",\n",
    "    \"lavoura_temporaria_censo_2006_2284\",\n",
    "    \"lavoura_permanente_censo_2017\",\n",
    "    \"extracao_vegetal_censo_2017\",\n",
    "    \"lavoura_temporaria_censo_2017\"\n",
    "]\n",
    "\n",
    "def get_query(table_name: str) -> str:\n",
    "    \"\"\"Generates a dynamic query for a specific table.\"\"\"\n",
    "    return f\"\"\"\n",
    "    SELECT \n",
    "        ano, \n",
    "        nome_regiao_integracao,\n",
    "        produto,  \n",
    "        -- Total\n",
    "        ROUND(SUM(quantidade_produzida), 2) as quantidade_produzida,\n",
    "        ROUND(SUM(valor_producao), 2) as valor_producao,\n",
    "        -- Comércio\n",
    "        ROUND(SUM(comercio_quantidade_produzida), 2) as comercio_quantidade_produzida,\n",
    "        ROUND(SUM(comercio_valor_producao), 2) as comercio_valor_producao\n",
    "    FROM pa_indexadores_producao_rural.{table_name}\n",
    "    GROUP BY 1, 2, 3\n",
    "    \"\"\"\n",
    "\n",
    "# --- PYDANTIC MODELS ---\n",
    "\n",
    "class VetoresProducaoRuralBase(BaseModel):\n",
    "    quantidade_produzida: float = Field(..., description=\"Quantidade total produzida na unidade de medida\")\n",
    "    valor_producao: float = Field(..., description=\"Valor financeiro da produção\")\n",
    "    comercio_quantidade_produzida: float = Field(..., description=\"Quantidade produzida para o comércio na unidade de medida\")\n",
    "    comercio_valor_producao: float = Field(..., description=\"Valor financeiro da produção\")\n",
    "\n",
    "# Hierarchy Definitions\n",
    "AnoMap = Dict[str, VetoresProducaoRuralBase]\n",
    "ProdutoMap = Dict[str, AnoMap]\n",
    "RegiaoMap = Dict[str, ProdutoMap]\n",
    "TipoPesquisaMap = Dict[str, RegiaoMap]\n",
    "NomePesquisaMap = Dict[str, TipoPesquisaMap]\n",
    "\n",
    "class VetoresProducaoRural(BaseModel):\n",
    "    vetores_producao_rural: NomePesquisaMap\n",
    "\n",
    "# --- PROCESSING LOGIC ---\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "def update_structure_from_df(accumulator: Dict, df: pd.DataFrame, tipo_pesquisa: str, nome_pesquisa: str) -> None:\n",
    "    \"\"\"\n",
    "    Updates the 'accumulator' dictionary in-place with data from the DataFrame.\n",
    "    \"\"\"\n",
    "    if df.empty:\n",
    "        print(f\"Warning: DataFrame for {nome_pesquisa} is empty.\")\n",
    "        return\n",
    "\n",
    "    df = df.fillna(0)\n",
    "\n",
    "    for row in df.itertuples(index=False):\n",
    "        regiao = getattr(row, 'nome_regiao_integracao')\n",
    "        produto = getattr(row, 'produto')\n",
    "        # Convert year to string for JSON compatibility\n",
    "        ano = str(int(getattr(row, 'ano'))) \n",
    "\n",
    "        # Recursive initialization (ensure keys exist)\n",
    "        # Structure: vetores_producao_rural -> nome_pesquisa -> tipo_pesquisa -> regiao -> produto -> ano\n",
    "        current_level = accumulator.setdefault(nome_pesquisa, {}) \\\n",
    "                                   .setdefault(tipo_pesquisa, {}) \\\n",
    "                                   .setdefault(regiao, {}) \\\n",
    "                                   .setdefault(produto, {})\n",
    "\n",
    "        # Create the data object\n",
    "        dados_ano = VetoresProducaoRuralBase(\n",
    "            quantidade_produzida=float(getattr(row, 'quantidade_produzida')),\n",
    "            valor_producao=float(getattr(row, 'valor_producao')),\n",
    "            comercio_quantidade_produzida=float(getattr(row, 'comercio_quantidade_produzida')),\n",
    "            comercio_valor_producao=float(getattr(row, 'comercio_valor_producao'))\n",
    "        ) \n",
    "        \n",
    "        # Assign data to the leaf node\n",
    "        current_level[ano] = dados_ano\n",
    "\n",
    "def save_pydantic_json(model: BaseModel, filename: str):\n",
    "    with open(filename, 'w', encoding='utf-8') as f:\n",
    "        f.write(model.model_dump_json(indent=4))\n",
    "    print(f\"Arquivo {filename} salvo com sucesso!\")\n",
    "\n",
    "# --- MAIN EXECUTION ---\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 1. Initialize the master accumulator dictionary\n",
    "    # This represents the internal structure of \"vetores_producao_rural\" field\n",
    "    master_data_accumulator: Dict[str, Any] = {}\n",
    "\n",
    "    with PostgresETL(\n",
    "        host='localhost', \n",
    "        database=os.getenv(\"DB_GOLD_ZONE\"), \n",
    "        user=os.getenv(\"POSTGRES_USER\"), \n",
    "        password=os.getenv(\"POSTGRES_PASSWORD\"),\n",
    "        schema='pa_indexadores_producao_rural'\n",
    "    ) as db:\n",
    "        \n",
    "        # 2. Loop through all tables\n",
    "        for table_name in CENSUS_TABLE_NAMES:\n",
    "            print(f\"Processando tabela: {table_name}...\")\n",
    "            \n",
    "            # Generate query for specific table\n",
    "            query = get_query(table_name)\n",
    "            \n",
    "            try:\n",
    "                # Extract\n",
    "                df_raw = db.download_data(query)\n",
    "                \n",
    "                # Transform (Accumulate into master dict)\n",
    "                # Note: We use the table name as 'nome_pesquisa'\n",
    "                update_structure_from_df(\n",
    "                    accumulator=master_data_accumulator, \n",
    "                    df=df_raw, \n",
    "                    tipo_pesquisa=\"censitaria\", \n",
    "                    nome_pesquisa=table_name\n",
    "                )\n",
    "                print(f\" -> {len(df_raw)} registros processados.\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Erro ao processar tabela {table_name}: {e}\")\n",
    "\n",
    "    # 3. Final Validation and Load\n",
    "    print(\"\\nIniciando validação final Pydantic...\")\n",
    "    try:\n",
    "        # Wrap the accumulated dictionary in the Root Model\n",
    "        modelo_consolidado = VetoresProducaoRural(vetores_producao_rural=master_data_accumulator)\n",
    "        \n",
    "        output_dir = 'json_output'\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        \n",
    "        # Save single consolidated file\n",
    "        save_pydantic_json(modelo_consolidado, f'{output_dir}/censos_consolidado_full.json')\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"FATAL: Erro na validação final dos dados: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0605da81",
   "metadata": {},
   "source": [
    "### Explorando problemas de compatibilização de produtos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d26189d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n",
      "WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n",
      "WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n",
      "WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n",
      "WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n",
      "WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['AndirobaOleo',\n",
       " 'CestinhaCarocinho',\n",
       " 'CajuAçuFruto',\n",
       " 'TaperebaFruto',\n",
       " 'Peneira',\n",
       " 'Alface',\n",
       " 'BacuriFruto',\n",
       " 'Portal',\n",
       " 'CestinhaHamburger',\n",
       " 'Cama',\n",
       " 'CascaMarapuana',\n",
       " 'Almofada',\n",
       " 'CastanhaDoPara',\n",
       " 'CascaAndiroba',\n",
       " 'Amendoim',\n",
       " 'SementeDeCumaru',\n",
       " 'Estorac',\n",
       " 'OleoPracaxi',\n",
       " 'Frango',\n",
       " 'SementeCumaru',\n",
       " 'VassouraArtesanal',\n",
       " 'PaneiroPequeno',\n",
       " 'LeiteAnani',\n",
       " 'Piso',\n",
       " 'Comodas',\n",
       " 'BacabaCaroco',\n",
       " 'CascaCarapanauba',\n",
       " 'FrangoCaipira',\n",
       " 'TucumaFruto',\n",
       " 'Paneiro',\n",
       " 'CascaBarbatimao',\n",
       " 'Pupunha',\n",
       " 'Mel',\n",
       " 'Fava',\n",
       " 'Abóbora',\n",
       " 'CestinhaDedal',\n",
       " 'LeiteJatoba',\n",
       " 'CarneBovina',\n",
       " 'Compensado',\n",
       " 'PimentaDoReino',\n",
       " 'PimeitaDoReino',\n",
       " 'Quiabo',\n",
       " 'PeneiraCorujinha',\n",
       " 'FavaDeJuca',\n",
       " 'CascaPariri',\n",
       " 'CheiroVerde',\n",
       " 'Degrau',\n",
       " 'Breu',\n",
       " 'Farinha',\n",
       " 'Peixe',\n",
       " 'Abacaxi',\n",
       " 'VassouraRegional',\n",
       " 'Paxiuba',\n",
       " 'LeiteSucuuba',\n",
       " 'Guarumã',\n",
       " 'AcaiCaroco',\n",
       " 'VassouraInaja',\n",
       " 'CaixaPia',\n",
       " 'Soja',\n",
       " 'Bau3',\n",
       " 'CurauaFibra',\n",
       " 'MadeiraVermelha',\n",
       " 'Caimbe',\n",
       " 'EscadaDeJabuti',\n",
       " 'Lenha',\n",
       " 'PaleteMadeira',\n",
       " 'Priprioca',\n",
       " 'CanaDeAçúcar',\n",
       " 'PaneiroGrande',\n",
       " 'Manteiga',\n",
       " 'Bezerro',\n",
       " 'Tomate',\n",
       " 'CascaJatoba',\n",
       " 'CascaSacaca',\n",
       " 'Murumuru',\n",
       " 'LeiteAmapa',\n",
       " 'Porta-Bica',\n",
       " 'CupuacuAmendoa',\n",
       " 'Bau1',\n",
       " 'OuricoCastanha',\n",
       " 'CascaAssacu',\n",
       " 'CestaJupati2',\n",
       " 'CascaCedro',\n",
       " 'BolsaArtesanal',\n",
       " 'Embirataia',\n",
       " 'AcaiFruto',\n",
       " 'Escrivanhinha',\n",
       " 'MuruciFruto',\n",
       " 'ArtesanatoRegionalLatex',\n",
       " 'Matapi',\n",
       " 'Tijolo8Furos',\n",
       " 'PiquiaFruto',\n",
       " 'Abajur',\n",
       " 'OleoPiquia',\n",
       " 'Cacau',\n",
       " 'CascaJatobá',\n",
       " 'CopaíbaOleo',\n",
       " 'Maracujá',\n",
       " 'LaminadosMadeira',\n",
       " 'CipóTimbui',\n",
       " 'Marapuama',\n",
       " 'Arroz',\n",
       " 'Carvão',\n",
       " 'CascaCajuacu',\n",
       " 'PaneiroGuarumã',\n",
       " 'OleoPataua',\n",
       " 'Peixede1º',\n",
       " 'PauDoce',\n",
       " 'CavaloMangaLarga',\n",
       " 'BorrachaLatex',\n",
       " 'Couve',\n",
       " 'Peixede1°',\n",
       " 'BuritiFruto',\n",
       " 'CastanhaDoPará',\n",
       " 'CastanhaDeCaju',\n",
       " 'Inaja',\n",
       " 'Esteira',\n",
       " 'PataDeVaca',\n",
       " 'Canarana',\n",
       " 'CascaUnhaDeGato',\n",
       " 'Cesto',\n",
       " 'Laranja',\n",
       " 'PaneirinhoParaTacaca',\n",
       " 'Lima',\n",
       " 'Mamão',\n",
       " 'Açúcar',\n",
       " 'Malva',\n",
       " 'Mesa',\n",
       " 'Cadeiras',\n",
       " 'Pimenta-do-reino',\n",
       " 'Peneira13Talas',\n",
       " 'Banana',\n",
       " 'Ucuuba',\n",
       " 'Capitiu',\n",
       " 'Leite',\n",
       " 'PalmitoInNatura',\n",
       " 'PratodeAlça',\n",
       " 'OleoAndiroba',\n",
       " 'Camarão',\n",
       " 'Tipiti',\n",
       " 'Mucaja',\n",
       " 'CipoTitica',\n",
       " 'CestaJupati1',\n",
       " 'Queijo',\n",
       " 'CascaBarbaTimao',\n",
       " 'CipóTorcido',\n",
       " 'Pari',\n",
       " 'BacabaFruto',\n",
       " 'CestoPalha',\n",
       " 'Arapari',\n",
       " 'CupuacuFruto',\n",
       " 'ArtesanatoRegional',\n",
       " 'OleoCurua',\n",
       " 'Peixede2ª',\n",
       " 'Castanha-do-Pará',\n",
       " 'Repolho',\n",
       " 'CascaAcoitaCavalo',\n",
       " 'AcaiInsumo',\n",
       " 'AlcoolAmidoHidratado',\n",
       " 'Peixede1ª',\n",
       " 'Quinarana',\n",
       " 'CascaAroeira',\n",
       " 'CacauAmendoa',\n",
       " 'Limão',\n",
       " 'Ovos',\n",
       " 'OlhoDeBoto',\n",
       " 'VassouradeTimbo',\n",
       " 'Peixe1ª',\n",
       " 'Laminado',\n",
       " 'Murure',\n",
       " 'Armário',\n",
       " 'MelDeAbelha',\n",
       " 'Biribá',\n",
       " 'OleoCastanhaDoBrasil',\n",
       " 'Portais',\n",
       " 'Acerola',\n",
       " 'Cupuaçu',\n",
       " 'CascaIpeRoxo',\n",
       " 'CascaVeronica',\n",
       " 'Goiaba',\n",
       " 'CarneSuina',\n",
       " 'PeixeSalgado',\n",
       " 'CacauFruto',\n",
       " 'Ração',\n",
       " 'AndirobaFruto',\n",
       " 'Miriti',\n",
       " 'SementeDeCupuacu',\n",
       " 'PeneiradeSaco',\n",
       " 'CestaPanetone',\n",
       " 'CascaCopaiba',\n",
       " 'CastanhaDoBrasil',\n",
       " 'InajáCaroço',\n",
       " 'Peixe2ª',\n",
       " 'SabaoDeCacau',\n",
       " 'Milho',\n",
       " 'CascaTaxi',\n",
       " 'Goma',\n",
       " 'Cipo',\n",
       " 'UxiFruto',\n",
       " 'Coco',\n",
       " 'Muruci',\n",
       " 'ArtesanatoMiriti',\n",
       " 'Cuia',\n",
       " 'Leitão',\n",
       " 'Bi-Cama',\n",
       " 'CestoBuriti',\n",
       " 'ChapeudePalha',\n",
       " 'Gondulas',\n",
       " 'CascaAcapurana',\n",
       " 'Pimentão',\n",
       " 'JucaFava',\n",
       " 'Carvao',\n",
       " 'Abacate',\n",
       " 'Tucupi',\n",
       " 'Abano',\n",
       " 'Peixede2°',\n",
       " 'Açaí',\n",
       " 'Melancia',\n",
       " 'CajaranaFruto',\n",
       " 'CascaPreciosa',\n",
       " 'CajuacuFruto',\n",
       " 'Portas',\n",
       " 'Madeira Branca',\n",
       " 'Feijão',\n",
       " 'Mari',\n",
       " 'ArtesanatoIndigena',\n",
       " 'CoratáAnajá',\n",
       " 'Peneira10Talas',\n",
       " 'Taperebá',\n",
       " 'Açai',\n",
       " 'CipoTimbo',\n",
       " 'PimentadoReino',\n",
       " 'Caranguejo',\n",
       " 'MuriciFruto',\n",
       " 'Mandioca',\n",
       " 'CestinhaPrato',\n",
       " 'Pataua',\n",
       " 'MadeiraBranca',\n",
       " 'GuardaRoupa',\n",
       " 'CascaUxi',\n",
       " 'CascaSucuuba',\n",
       " 'Urucum',\n",
       " 'Andiroba',\n",
       " 'Porta',\n",
       " 'Tijolo2Furos',\n",
       " 'CupuaçuFruto',\n",
       " 'Peixede2º',\n",
       " 'OleoCopaiba',\n",
       " 'Bau2',\n",
       " 'ChapeuPalha',\n",
       " 'Uxi',\n",
       " 'Pimenta']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "path = os.path.join(os.getcwd(), 'temp')\n",
    "\n",
    "\n",
    "path_tbs_extensa = [file for file in os.listdir(path) if file.startswith('Tb')]\n",
    "\n",
    "tabela_produto_dict = {}\n",
    "\n",
    "for tabela in path_tbs_extensa:\n",
    "    tabela_path = os.path.join(path, tabela)\n",
    "    try:\n",
    "        df = pd.read_excel(tabela_path)\n",
    "        if 'Produto' in df.columns:\n",
    "            produtos_unicos = df['Produto'].dropna().unique().tolist()\n",
    "            tabela_produto_dict[tabela] = produtos_unicos\n",
    "        else:\n",
    "            print(f\"A tabela {tabela} não possui a coluna 'Produto'.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao processar a tabela {tabela}: {e}\")\n",
    "\n",
    "\n",
    "produtos = list(set(item for sublist in tabela_produto_dict.values() for item in sublist))\n",
    "produtos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "99df4b26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n",
      "WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n",
      "WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n",
      "WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n",
      "WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n",
      "WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "path = os.path.join(os.getcwd(), 'temp')\n",
    "path_tbs_extensa = [file for file in os.listdir(path) if file.startswith('Tb')]\n",
    "\n",
    "tabela_produto_dict = {}\n",
    "\n",
    "soma_global = {}\n",
    "\n",
    "for tabela in path_tbs_extensa:\n",
    "    tabela_path = os.path.join(path, tabela)\n",
    "    try:\n",
    "        df = pd.read_excel(tabela_path)\n",
    "\n",
    "        if all(col in df.columns for col in ['Produto', 'Unidade', 'Quantidade']):\n",
    "            df_filtrado = df[['Produto', 'Unidade', 'Quantidade']].dropna()\n",
    "            df_filtrado['Unidade'] = df_filtrado['Unidade'].str.lower()\n",
    "            df_filtrado['Quantidade'] = pd.to_numeric(df_filtrado['Quantidade'], errors='coerce').fillna(0)\n",
    "\n",
    "            agrupado = (\n",
    "                df_filtrado\n",
    "                .groupby(['Produto', 'Unidade'], dropna=True)['Quantidade']\n",
    "                .sum()\n",
    "                .reset_index()\n",
    "            )\n",
    "\n",
    "            tabela_dict = {}\n",
    "\n",
    "            for _, row in agrupado.iterrows():\n",
    "                produto = row['Produto']\n",
    "                unidade = row['Unidade']\n",
    "                quantidade = row['Quantidade']\n",
    "\n",
    "                if produto not in tabela_dict:\n",
    "                    tabela_dict[produto] = {}\n",
    "                tabela_dict[produto][unidade] = quantidade\n",
    "\n",
    "                if produto not in soma_global:\n",
    "                    soma_global[produto] = {}\n",
    "                if unidade not in soma_global[produto]:\n",
    "                    soma_global[produto][unidade] = 0\n",
    "                soma_global[produto][unidade] += quantidade\n",
    "\n",
    "            tabela_produto_dict[tabela] = tabela_dict\n",
    "\n",
    "        else:\n",
    "            print(f\"A tabela {tabela} não possui todas as colunas necessárias.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao processar a tabela {tabela}: {e}\")\n",
    "\n",
    "linhas = []\n",
    "\n",
    "for produto, unidades in soma_global.items():\n",
    "    for unidade, quantidade in unidades.items():\n",
    "        linhas.append({\n",
    "            'produto': produto,\n",
    "            'unidade': unidade,\n",
    "            'soma_quantidade': quantidade\n",
    "        })\n",
    "\n",
    "df_resultado = pd.DataFrame(linhas)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e38a531",
   "metadata": {},
   "source": [
    "### Algoritmo de indexação do trabalho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84a61585",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "ano",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "nome_regiao_integracao",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "produto",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "quantidade_produzida",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "valor_producao",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "ref": "9502e1b0-4cef-4ab7-acf8-96eb8228c794",
       "rows": [
        [
         "0",
         "2006",
         "Tapajós",
         "pupunha-cacho",
         "1.00",
         "1.80"
        ],
        [
         "1",
         "2006",
         "Lago de Tucuruí",
         "pitanga",
         "0.00",
         "0.00"
        ],
        [
         "2",
         "2006",
         "Carajás",
         "lichia",
         "0.00",
         "0.00"
        ],
        [
         "3",
         "2006",
         "Carajás",
         "jabuticaba",
         "0.00",
         "0.00"
        ],
        [
         "4",
         "2006",
         "Xingu",
         "guaraná",
         "0.00",
         "0.11"
        ],
        [
         "5",
         "2006",
         "Xingu",
         "abacate",
         "55.00",
         "26.49"
        ],
        [
         "6",
         "2006",
         "Tocantins",
         "urucum-semente",
         "6.00",
         "6.94"
        ],
        [
         "7",
         "2006",
         "Carajás",
         "cravo da índia",
         "0.00",
         "0.00"
        ],
        [
         "8",
         "2006",
         "Marajó",
         "ameixa",
         "0.00",
         "0.00"
        ],
        [
         "9",
         "2006",
         "NaN",
         "pimenta-do-reino",
         "10574.00",
         "47688.94"
        ],
        [
         "10",
         "2006",
         "Baixo Amazonas",
         "mamão",
         "781.00",
         "823.27"
        ],
        [
         "11",
         "2006",
         "Lago de Tucuruí",
         "acerola",
         "4.00",
         "3.66"
        ],
        [
         "12",
         "2006",
         "NaN",
         "caju-mudas",
         "0.00",
         "1.00"
        ],
        [
         "13",
         "2006",
         "Tocantins",
         "fruta-de-conde",
         "0.00",
         "0.00"
        ],
        [
         "14",
         "2006",
         "Marajó",
         "erva-mate",
         "0.00",
         "0.00"
        ],
        [
         "15",
         "2006",
         "Rio Capim",
         "maracujá",
         "543.00",
         "454.07"
        ],
        [
         "16",
         "2006",
         "Tocantins",
         "nectarina",
         "0.00",
         "0.00"
        ],
        [
         "17",
         "2006",
         "Carajás",
         "louro-folha",
         "0.00",
         "0.00"
        ],
        [
         "18",
         "2006",
         "Marajó",
         "guaraná",
         "0.00",
         "0.00"
        ],
        [
         "19",
         "2006",
         "Araguaia",
         "figo",
         "0.00",
         "0.00"
        ],
        [
         "20",
         "2006",
         "Tapajós",
         "maracujá",
         "0.00",
         "0.00"
        ],
        [
         "21",
         "2006",
         "Rio Capim",
         "fruta-de-conde",
         "0.00",
         "0.00"
        ],
        [
         "22",
         "2006",
         "Tocantins",
         "amora-folha",
         "0.00",
         "0.00"
        ],
        [
         "23",
         "2006",
         "Araguaia",
         "amora-folha",
         "0.00",
         "0.00"
        ],
        [
         "24",
         "2006",
         "Guamá",
         "louro-folha",
         "0.00",
         "0.00"
        ],
        [
         "25",
         "2006",
         "Araguaia",
         "maracujá",
         "14.00",
         "7.88"
        ],
        [
         "26",
         "2006",
         "Guajará",
         "palmito",
         "0.00",
         "0.00"
        ],
        [
         "27",
         "2006",
         "Rio Capim",
         "abacate",
         "5.00",
         "5.33"
        ],
        [
         "28",
         "2006",
         "Carajás",
         "guaraná",
         "0.00",
         "0.00"
        ],
        [
         "29",
         "2006",
         "Marajó",
         "borracha-latéx coagulado",
         "0.00",
         "10.99"
        ],
        [
         "30",
         "2006",
         "Tapajós",
         "lichia",
         "0.00",
         "0.00"
        ],
        [
         "31",
         "2006",
         "Marajó",
         "lichia",
         "0.00",
         "0.00"
        ],
        [
         "32",
         "2006",
         "Marajó",
         "cacau-amêndoa",
         "2159.00",
         "3797.67"
        ],
        [
         "33",
         "2006",
         "Tocantins",
         "café canephora-grão",
         "30.00",
         "38.43"
        ],
        [
         "34",
         "2006",
         "Araguaia",
         "nectarina",
         "0.00",
         "0.00"
        ],
        [
         "35",
         "2006",
         "Xingu",
         "frutas cítricas-mudas",
         "0.00",
         "0.00"
        ],
        [
         "36",
         "2006",
         "Araguaia",
         "pimenta-do-reino",
         "1677.00",
         "5627.41"
        ],
        [
         "37",
         "2006",
         "Baixo Amazonas",
         "palmito",
         "7.00",
         "38.65"
        ],
        [
         "38",
         "2006",
         "Baixo Amazonas",
         "agave, sisal-fibra",
         "0.00",
         "0.00"
        ],
        [
         "39",
         "2006",
         "Tocantins",
         "pitanga",
         "0.00",
         "0.00"
        ],
        [
         "40",
         "2006",
         "Tocantins",
         "jaca",
         "0.00",
         "0.00"
        ],
        [
         "41",
         "2006",
         "Lago de Tucuruí",
         "outros produtos lavoura permanente-mudas",
         "0.00",
         "0.00"
        ],
        [
         "42",
         "2006",
         "Guajará",
         "borracha-latéx coagulado",
         "0.00",
         "0.00"
        ],
        [
         "43",
         "2006",
         "Tapajós",
         "nectarina",
         "0.00",
         "0.00"
        ],
        [
         "44",
         "2006",
         "Carajás",
         "goiaba",
         "2.00",
         "1.36"
        ],
        [
         "45",
         "2006",
         "Xingu",
         "urucum-semente",
         "4.00",
         "8.70"
        ],
        [
         "46",
         "2006",
         "Tocantins",
         "outros produtos lavoura permanente-mudas",
         "0.00",
         "0.00"
        ],
        [
         "47",
         "2006",
         "Carajás",
         "pera",
         "0.00",
         "0.00"
        ],
        [
         "48",
         "2006",
         "Tocantins",
         "abacate",
         "1.00",
         "6.30"
        ],
        [
         "49",
         "2006",
         "Rio Capim",
         "palmito",
         "7.00",
         "38.65"
        ]
       ],
       "shape": {
        "columns": 5,
        "rows": 858
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ano</th>\n",
       "      <th>nome_regiao_integracao</th>\n",
       "      <th>produto</th>\n",
       "      <th>quantidade_produzida</th>\n",
       "      <th>valor_producao</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2006</td>\n",
       "      <td>Tapajós</td>\n",
       "      <td>pupunha-cacho</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2006</td>\n",
       "      <td>Lago de Tucuruí</td>\n",
       "      <td>pitanga</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2006</td>\n",
       "      <td>Carajás</td>\n",
       "      <td>lichia</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2006</td>\n",
       "      <td>Carajás</td>\n",
       "      <td>jabuticaba</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2006</td>\n",
       "      <td>Xingu</td>\n",
       "      <td>guaraná</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>853</th>\n",
       "      <td>2006</td>\n",
       "      <td>Carajás</td>\n",
       "      <td>nectarina</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>854</th>\n",
       "      <td>2006</td>\n",
       "      <td>Lago de Tucuruí</td>\n",
       "      <td>pera</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>855</th>\n",
       "      <td>2006</td>\n",
       "      <td>NaN</td>\n",
       "      <td>romã</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>856</th>\n",
       "      <td>2006</td>\n",
       "      <td>Rio Capim</td>\n",
       "      <td>nêspera</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>857</th>\n",
       "      <td>2006</td>\n",
       "      <td>Rio Capim</td>\n",
       "      <td>camu-camu</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>858 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ano nome_regiao_integracao        produto quantidade_produzida  \\\n",
       "0    2006                Tapajós  pupunha-cacho                 1.00   \n",
       "1    2006        Lago de Tucuruí        pitanga                 0.00   \n",
       "2    2006                Carajás         lichia                 0.00   \n",
       "3    2006                Carajás     jabuticaba                 0.00   \n",
       "4    2006                  Xingu        guaraná                 0.00   \n",
       "..    ...                    ...            ...                  ...   \n",
       "853  2006                Carajás      nectarina                 0.00   \n",
       "854  2006        Lago de Tucuruí           pera                 0.00   \n",
       "855  2006                    NaN           romã                 0.00   \n",
       "856  2006              Rio Capim        nêspera                 0.00   \n",
       "857  2006              Rio Capim      camu-camu                 0.00   \n",
       "\n",
       "    valor_producao  \n",
       "0             1.80  \n",
       "1             0.00  \n",
       "2             0.00  \n",
       "3             0.00  \n",
       "4             0.11  \n",
       "..             ...  \n",
       "853           0.00  \n",
       "854           0.00  \n",
       "855           0.00  \n",
       "856           0.00  \n",
       "857           0.00  \n",
       "\n",
       "[858 rows x 5 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lavoura_permanente_pam_query \n",
    "lavoura_permanente_censo_2017_query \n",
    "lavoura_permanente_censo_2006_query\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "alfa-data",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
